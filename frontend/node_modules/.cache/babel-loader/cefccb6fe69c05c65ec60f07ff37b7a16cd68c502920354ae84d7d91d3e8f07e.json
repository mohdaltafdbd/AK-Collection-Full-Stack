{"ast":null,"code":"'use strict';\n\nconst util = require('util');\nconst crypto = require('crypto');\nconst fs = require('@npmcli/fs');\nconst Minipass = require('minipass');\nconst path = require('path');\nconst ssri = require('ssri');\nconst uniqueFilename = require('unique-filename');\nconst contentPath = require('./content/path');\nconst fixOwner = require('./util/fix-owner');\nconst hashToSegments = require('./util/hash-to-segments');\nconst indexV = require('../package.json')['cache-version'].index;\nconst moveFile = require('@npmcli/move-file');\nconst _rimraf = require('rimraf');\nconst rimraf = util.promisify(_rimraf);\nrimraf.sync = _rimraf.sync;\nmodule.exports.NotFoundError = class NotFoundError extends Error {\n  constructor(cache, key) {\n    super(`No cache entry for ${key} found in ${cache}`);\n    this.code = 'ENOENT';\n    this.cache = cache;\n    this.key = key;\n  }\n};\nmodule.exports.compact = compact;\nasync function compact(cache, key, matchFn) {\n  let opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  const bucket = bucketPath(cache, key);\n  const entries = await bucketEntries(bucket);\n  const newEntries = [];\n  // we loop backwards because the bottom-most result is the newest\n  // since we add new entries with appendFile\n  for (let i = entries.length - 1; i >= 0; --i) {\n    const entry = entries[i];\n    // a null integrity could mean either a delete was appended\n    // or the user has simply stored an index that does not map\n    // to any content. we determine if the user wants to keep the\n    // null integrity based on the validateEntry function passed in options.\n    // if the integrity is null and no validateEntry is provided, we break\n    // as we consider the null integrity to be a deletion of everything\n    // that came before it.\n    if (entry.integrity === null && !opts.validateEntry) {\n      break;\n    }\n\n    // if this entry is valid, and it is either the first entry or\n    // the newEntries array doesn't already include an entry that\n    // matches this one based on the provided matchFn, then we add\n    // it to the beginning of our list\n    if ((!opts.validateEntry || opts.validateEntry(entry) === true) && (newEntries.length === 0 || !newEntries.find(oldEntry => matchFn(oldEntry, entry)))) {\n      newEntries.unshift(entry);\n    }\n  }\n  const newIndex = '\\n' + newEntries.map(entry => {\n    const stringified = JSON.stringify(entry);\n    const hash = hashEntry(stringified);\n    return `${hash}\\t${stringified}`;\n  }).join('\\n');\n  const setup = async () => {\n    const target = uniqueFilename(path.join(cache, 'tmp'), opts.tmpPrefix);\n    await fixOwner.mkdirfix(cache, path.dirname(target));\n    return {\n      target,\n      moved: false\n    };\n  };\n  const teardown = async tmp => {\n    if (!tmp.moved) {\n      return rimraf(tmp.target);\n    }\n  };\n  const write = async tmp => {\n    await fs.writeFile(tmp.target, newIndex, {\n      flag: 'wx'\n    });\n    await fixOwner.mkdirfix(cache, path.dirname(bucket));\n    // we use @npmcli/move-file directly here because we\n    // want to overwrite the existing file\n    await moveFile(tmp.target, bucket);\n    tmp.moved = true;\n    try {\n      await fixOwner.chownr(cache, bucket);\n    } catch (err) {\n      if (err.code !== 'ENOENT') {\n        throw err;\n      }\n    }\n  };\n\n  // write the file atomically\n  const tmp = await setup();\n  try {\n    await write(tmp);\n  } finally {\n    await teardown(tmp);\n  }\n\n  // we reverse the list we generated such that the newest\n  // entries come first in order to make looping through them easier\n  // the true passed to formatEntry tells it to keep null\n  // integrity values, if they made it this far it's because\n  // validateEntry returned true, and as such we should return it\n  return newEntries.reverse().map(entry => formatEntry(cache, entry, true));\n}\nmodule.exports.insert = insert;\nasync function insert(cache, key, integrity) {\n  let opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  const {\n    metadata,\n    size\n  } = opts;\n  const bucket = bucketPath(cache, key);\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata\n  };\n  try {\n    await fixOwner.mkdirfix(cache, path.dirname(bucket));\n    const stringified = JSON.stringify(entry);\n    // NOTE - Cleverness ahoy!\n    //\n    // This works because it's tremendously unlikely for an entry to corrupt\n    // another while still preserving the string length of the JSON in\n    // question. So, we just slap the length in there and verify it on read.\n    //\n    // Thanks to @isaacs for the whiteboarding session that ended up with\n    // this.\n    await fs.appendFile(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`);\n    await fixOwner.chownr(cache, bucket);\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return undefined;\n    }\n    throw err;\n    // There's a class of race conditions that happen when things get deleted\n    // during fixOwner, or between the two mkdirfix/chownr calls.\n    //\n    // It's perfectly fine to just not bother in those cases and lie\n    // that the index entry was written. Because it's a cache.\n  }\n\n  return formatEntry(cache, entry);\n}\nmodule.exports.insert.sync = insertSync;\nfunction insertSync(cache, key, integrity) {\n  let opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  const {\n    metadata,\n    size\n  } = opts;\n  const bucket = bucketPath(cache, key);\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata\n  };\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket));\n  const stringified = JSON.stringify(entry);\n  fs.appendFileSync(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`);\n  try {\n    fixOwner.chownr.sync(cache, bucket);\n  } catch (err) {\n    if (err.code !== 'ENOENT') {\n      throw err;\n    }\n  }\n  return formatEntry(cache, entry);\n}\nmodule.exports.find = find;\nasync function find(cache, key) {\n  const bucket = bucketPath(cache, key);\n  try {\n    const entries = await bucketEntries(bucket);\n    return entries.reduce((latest, next) => {\n      if (next && next.key === key) {\n        return formatEntry(cache, next);\n      } else {\n        return latest;\n      }\n    }, null);\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return null;\n    } else {\n      throw err;\n    }\n  }\n}\nmodule.exports.find.sync = findSync;\nfunction findSync(cache, key) {\n  const bucket = bucketPath(cache, key);\n  try {\n    return bucketEntriesSync(bucket).reduce((latest, next) => {\n      if (next && next.key === key) {\n        return formatEntry(cache, next);\n      } else {\n        return latest;\n      }\n    }, null);\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return null;\n    } else {\n      throw err;\n    }\n  }\n}\nmodule.exports.delete = del;\nfunction del(cache, key) {\n  let opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  if (!opts.removeFully) {\n    return insert(cache, key, null, opts);\n  }\n  const bucket = bucketPath(cache, key);\n  return rimraf(bucket);\n}\nmodule.exports.delete.sync = delSync;\nfunction delSync(cache, key) {\n  let opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  if (!opts.removeFully) {\n    return insertSync(cache, key, null, opts);\n  }\n  const bucket = bucketPath(cache, key);\n  return rimraf.sync(bucket);\n}\nmodule.exports.lsStream = lsStream;\nfunction lsStream(cache) {\n  const indexDir = bucketDir(cache);\n  const stream = new Minipass({\n    objectMode: true\n  });\n\n  // Set all this up to run on the stream and then just return the stream\n  Promise.resolve().then(async () => {\n    const buckets = await readdirOrEmpty(indexDir);\n    await Promise.all(buckets.map(async bucket => {\n      const bucketPath = path.join(indexDir, bucket);\n      const subbuckets = await readdirOrEmpty(bucketPath);\n      await Promise.all(subbuckets.map(async subbucket => {\n        const subbucketPath = path.join(bucketPath, subbucket);\n\n        // \"/cachename/<bucket 0xFF>/<bucket 0xFF>./*\"\n        const subbucketEntries = await readdirOrEmpty(subbucketPath);\n        await Promise.all(subbucketEntries.map(async entry => {\n          const entryPath = path.join(subbucketPath, entry);\n          try {\n            const entries = await bucketEntries(entryPath);\n            // using a Map here prevents duplicate keys from showing up\n            // twice, I guess?\n            const reduced = entries.reduce((acc, entry) => {\n              acc.set(entry.key, entry);\n              return acc;\n            }, new Map());\n            // reduced is a map of key => entry\n            for (const entry of reduced.values()) {\n              const formatted = formatEntry(cache, entry);\n              if (formatted) {\n                stream.write(formatted);\n              }\n            }\n          } catch (err) {\n            if (err.code === 'ENOENT') {\n              return undefined;\n            }\n            throw err;\n          }\n        }));\n      }));\n    }));\n    stream.end();\n    return stream;\n  }).catch(err => stream.emit('error', err));\n  return stream;\n}\nmodule.exports.ls = ls;\nasync function ls(cache) {\n  const entries = await lsStream(cache).collect();\n  return entries.reduce((acc, xs) => {\n    acc[xs.key] = xs;\n    return acc;\n  }, {});\n}\nmodule.exports.bucketEntries = bucketEntries;\nasync function bucketEntries(bucket, filter) {\n  const data = await fs.readFile(bucket, 'utf8');\n  return _bucketEntries(data, filter);\n}\nmodule.exports.bucketEntries.sync = bucketEntriesSync;\nfunction bucketEntriesSync(bucket, filter) {\n  const data = fs.readFileSync(bucket, 'utf8');\n  return _bucketEntries(data, filter);\n}\nfunction _bucketEntries(data, filter) {\n  const entries = [];\n  data.split('\\n').forEach(entry => {\n    if (!entry) {\n      return;\n    }\n    const pieces = entry.split('\\t');\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return;\n    }\n    let obj;\n    try {\n      obj = JSON.parse(pieces[1]);\n    } catch (e) {\n      // Entry is corrupted!\n      return;\n    }\n    if (obj) {\n      entries.push(obj);\n    }\n  });\n  return entries;\n}\nmodule.exports.bucketDir = bucketDir;\nfunction bucketDir(cache) {\n  return path.join(cache, `index-v${indexV}`);\n}\nmodule.exports.bucketPath = bucketPath;\nfunction bucketPath(cache, key) {\n  const hashed = hashKey(key);\n  return path.join.apply(path, [bucketDir(cache)].concat(hashToSegments(hashed)));\n}\nmodule.exports.hashKey = hashKey;\nfunction hashKey(key) {\n  return hash(key, 'sha256');\n}\nmodule.exports.hashEntry = hashEntry;\nfunction hashEntry(str) {\n  return hash(str, 'sha1');\n}\nfunction hash(str, digest) {\n  return crypto.createHash(digest).update(str).digest('hex');\n}\nfunction formatEntry(cache, entry, keepAll) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity && !keepAll) {\n    return null;\n  }\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: entry.integrity ? contentPath(cache, entry.integrity) : undefined,\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata\n  };\n}\nfunction readdirOrEmpty(dir) {\n  return fs.readdir(dir).catch(err => {\n    if (err.code === 'ENOENT' || err.code === 'ENOTDIR') {\n      return [];\n    }\n    throw err;\n  });\n}","map":{"version":3,"names":["util","require","crypto","fs","Minipass","path","ssri","uniqueFilename","contentPath","fixOwner","hashToSegments","indexV","index","moveFile","_rimraf","rimraf","promisify","sync","module","exports","NotFoundError","Error","constructor","cache","key","code","compact","matchFn","opts","bucket","bucketPath","entries","bucketEntries","newEntries","i","length","entry","integrity","validateEntry","find","oldEntry","unshift","newIndex","map","stringified","JSON","stringify","hash","hashEntry","join","setup","target","tmpPrefix","mkdirfix","dirname","moved","teardown","tmp","write","writeFile","flag","chownr","err","reverse","formatEntry","insert","metadata","size","time","Date","now","appendFile","undefined","insertSync","appendFileSync","reduce","latest","next","findSync","bucketEntriesSync","delete","del","removeFully","delSync","lsStream","indexDir","bucketDir","stream","objectMode","Promise","resolve","then","buckets","readdirOrEmpty","all","subbuckets","subbucket","subbucketPath","subbucketEntries","entryPath","reduced","acc","set","Map","values","formatted","end","catch","emit","ls","collect","xs","filter","data","readFile","_bucketEntries","readFileSync","split","forEach","pieces","obj","parse","e","push","hashed","hashKey","apply","concat","str","digest","createHash","update","keepAll","dir","readdir"],"sources":["/Users/altafziya/Desktop/new project/ak collection/frontend/node_modules/cacache/lib/entry-index.js"],"sourcesContent":["'use strict'\n\nconst util = require('util')\nconst crypto = require('crypto')\nconst fs = require('@npmcli/fs')\nconst Minipass = require('minipass')\nconst path = require('path')\nconst ssri = require('ssri')\nconst uniqueFilename = require('unique-filename')\n\nconst contentPath = require('./content/path')\nconst fixOwner = require('./util/fix-owner')\nconst hashToSegments = require('./util/hash-to-segments')\nconst indexV = require('../package.json')['cache-version'].index\nconst moveFile = require('@npmcli/move-file')\nconst _rimraf = require('rimraf')\nconst rimraf = util.promisify(_rimraf)\nrimraf.sync = _rimraf.sync\n\nmodule.exports.NotFoundError = class NotFoundError extends Error {\n  constructor (cache, key) {\n    super(`No cache entry for ${key} found in ${cache}`)\n    this.code = 'ENOENT'\n    this.cache = cache\n    this.key = key\n  }\n}\n\nmodule.exports.compact = compact\n\nasync function compact (cache, key, matchFn, opts = {}) {\n  const bucket = bucketPath(cache, key)\n  const entries = await bucketEntries(bucket)\n  const newEntries = []\n  // we loop backwards because the bottom-most result is the newest\n  // since we add new entries with appendFile\n  for (let i = entries.length - 1; i >= 0; --i) {\n    const entry = entries[i]\n    // a null integrity could mean either a delete was appended\n    // or the user has simply stored an index that does not map\n    // to any content. we determine if the user wants to keep the\n    // null integrity based on the validateEntry function passed in options.\n    // if the integrity is null and no validateEntry is provided, we break\n    // as we consider the null integrity to be a deletion of everything\n    // that came before it.\n    if (entry.integrity === null && !opts.validateEntry) {\n      break\n    }\n\n    // if this entry is valid, and it is either the first entry or\n    // the newEntries array doesn't already include an entry that\n    // matches this one based on the provided matchFn, then we add\n    // it to the beginning of our list\n    if ((!opts.validateEntry || opts.validateEntry(entry) === true) &&\n      (newEntries.length === 0 ||\n        !newEntries.find((oldEntry) => matchFn(oldEntry, entry)))) {\n      newEntries.unshift(entry)\n    }\n  }\n\n  const newIndex = '\\n' + newEntries.map((entry) => {\n    const stringified = JSON.stringify(entry)\n    const hash = hashEntry(stringified)\n    return `${hash}\\t${stringified}`\n  }).join('\\n')\n\n  const setup = async () => {\n    const target = uniqueFilename(path.join(cache, 'tmp'), opts.tmpPrefix)\n    await fixOwner.mkdirfix(cache, path.dirname(target))\n    return {\n      target,\n      moved: false,\n    }\n  }\n\n  const teardown = async (tmp) => {\n    if (!tmp.moved) {\n      return rimraf(tmp.target)\n    }\n  }\n\n  const write = async (tmp) => {\n    await fs.writeFile(tmp.target, newIndex, { flag: 'wx' })\n    await fixOwner.mkdirfix(cache, path.dirname(bucket))\n    // we use @npmcli/move-file directly here because we\n    // want to overwrite the existing file\n    await moveFile(tmp.target, bucket)\n    tmp.moved = true\n    try {\n      await fixOwner.chownr(cache, bucket)\n    } catch (err) {\n      if (err.code !== 'ENOENT') {\n        throw err\n      }\n    }\n  }\n\n  // write the file atomically\n  const tmp = await setup()\n  try {\n    await write(tmp)\n  } finally {\n    await teardown(tmp)\n  }\n\n  // we reverse the list we generated such that the newest\n  // entries come first in order to make looping through them easier\n  // the true passed to formatEntry tells it to keep null\n  // integrity values, if they made it this far it's because\n  // validateEntry returned true, and as such we should return it\n  return newEntries.reverse().map((entry) => formatEntry(cache, entry, true))\n}\n\nmodule.exports.insert = insert\n\nasync function insert (cache, key, integrity, opts = {}) {\n  const { metadata, size } = opts\n  const bucket = bucketPath(cache, key)\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata,\n  }\n  try {\n    await fixOwner.mkdirfix(cache, path.dirname(bucket))\n    const stringified = JSON.stringify(entry)\n    // NOTE - Cleverness ahoy!\n    //\n    // This works because it's tremendously unlikely for an entry to corrupt\n    // another while still preserving the string length of the JSON in\n    // question. So, we just slap the length in there and verify it on read.\n    //\n    // Thanks to @isaacs for the whiteboarding session that ended up with\n    // this.\n    await fs.appendFile(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`)\n    await fixOwner.chownr(cache, bucket)\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return undefined\n    }\n\n    throw err\n    // There's a class of race conditions that happen when things get deleted\n    // during fixOwner, or between the two mkdirfix/chownr calls.\n    //\n    // It's perfectly fine to just not bother in those cases and lie\n    // that the index entry was written. Because it's a cache.\n  }\n  return formatEntry(cache, entry)\n}\n\nmodule.exports.insert.sync = insertSync\n\nfunction insertSync (cache, key, integrity, opts = {}) {\n  const { metadata, size } = opts\n  const bucket = bucketPath(cache, key)\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata,\n  }\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket))\n  const stringified = JSON.stringify(entry)\n  fs.appendFileSync(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`)\n  try {\n    fixOwner.chownr.sync(cache, bucket)\n  } catch (err) {\n    if (err.code !== 'ENOENT') {\n      throw err\n    }\n  }\n  return formatEntry(cache, entry)\n}\n\nmodule.exports.find = find\n\nasync function find (cache, key) {\n  const bucket = bucketPath(cache, key)\n  try {\n    const entries = await bucketEntries(bucket)\n    return entries.reduce((latest, next) => {\n      if (next && next.key === key) {\n        return formatEntry(cache, next)\n      } else {\n        return latest\n      }\n    }, null)\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return null\n    } else {\n      throw err\n    }\n  }\n}\n\nmodule.exports.find.sync = findSync\n\nfunction findSync (cache, key) {\n  const bucket = bucketPath(cache, key)\n  try {\n    return bucketEntriesSync(bucket).reduce((latest, next) => {\n      if (next && next.key === key) {\n        return formatEntry(cache, next)\n      } else {\n        return latest\n      }\n    }, null)\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return null\n    } else {\n      throw err\n    }\n  }\n}\n\nmodule.exports.delete = del\n\nfunction del (cache, key, opts = {}) {\n  if (!opts.removeFully) {\n    return insert(cache, key, null, opts)\n  }\n\n  const bucket = bucketPath(cache, key)\n  return rimraf(bucket)\n}\n\nmodule.exports.delete.sync = delSync\n\nfunction delSync (cache, key, opts = {}) {\n  if (!opts.removeFully) {\n    return insertSync(cache, key, null, opts)\n  }\n\n  const bucket = bucketPath(cache, key)\n  return rimraf.sync(bucket)\n}\n\nmodule.exports.lsStream = lsStream\n\nfunction lsStream (cache) {\n  const indexDir = bucketDir(cache)\n  const stream = new Minipass({ objectMode: true })\n\n  // Set all this up to run on the stream and then just return the stream\n  Promise.resolve().then(async () => {\n    const buckets = await readdirOrEmpty(indexDir)\n    await Promise.all(buckets.map(async (bucket) => {\n      const bucketPath = path.join(indexDir, bucket)\n      const subbuckets = await readdirOrEmpty(bucketPath)\n      await Promise.all(subbuckets.map(async (subbucket) => {\n        const subbucketPath = path.join(bucketPath, subbucket)\n\n        // \"/cachename/<bucket 0xFF>/<bucket 0xFF>./*\"\n        const subbucketEntries = await readdirOrEmpty(subbucketPath)\n        await Promise.all(subbucketEntries.map(async (entry) => {\n          const entryPath = path.join(subbucketPath, entry)\n          try {\n            const entries = await bucketEntries(entryPath)\n            // using a Map here prevents duplicate keys from showing up\n            // twice, I guess?\n            const reduced = entries.reduce((acc, entry) => {\n              acc.set(entry.key, entry)\n              return acc\n            }, new Map())\n            // reduced is a map of key => entry\n            for (const entry of reduced.values()) {\n              const formatted = formatEntry(cache, entry)\n              if (formatted) {\n                stream.write(formatted)\n              }\n            }\n          } catch (err) {\n            if (err.code === 'ENOENT') {\n              return undefined\n            }\n            throw err\n          }\n        }))\n      }))\n    }))\n    stream.end()\n    return stream\n  }).catch(err => stream.emit('error', err))\n\n  return stream\n}\n\nmodule.exports.ls = ls\n\nasync function ls (cache) {\n  const entries = await lsStream(cache).collect()\n  return entries.reduce((acc, xs) => {\n    acc[xs.key] = xs\n    return acc\n  }, {})\n}\n\nmodule.exports.bucketEntries = bucketEntries\n\nasync function bucketEntries (bucket, filter) {\n  const data = await fs.readFile(bucket, 'utf8')\n  return _bucketEntries(data, filter)\n}\n\nmodule.exports.bucketEntries.sync = bucketEntriesSync\n\nfunction bucketEntriesSync (bucket, filter) {\n  const data = fs.readFileSync(bucket, 'utf8')\n  return _bucketEntries(data, filter)\n}\n\nfunction _bucketEntries (data, filter) {\n  const entries = []\n  data.split('\\n').forEach((entry) => {\n    if (!entry) {\n      return\n    }\n\n    const pieces = entry.split('\\t')\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return\n    }\n    let obj\n    try {\n      obj = JSON.parse(pieces[1])\n    } catch (e) {\n      // Entry is corrupted!\n      return\n    }\n    if (obj) {\n      entries.push(obj)\n    }\n  })\n  return entries\n}\n\nmodule.exports.bucketDir = bucketDir\n\nfunction bucketDir (cache) {\n  return path.join(cache, `index-v${indexV}`)\n}\n\nmodule.exports.bucketPath = bucketPath\n\nfunction bucketPath (cache, key) {\n  const hashed = hashKey(key)\n  return path.join.apply(\n    path,\n    [bucketDir(cache)].concat(hashToSegments(hashed))\n  )\n}\n\nmodule.exports.hashKey = hashKey\n\nfunction hashKey (key) {\n  return hash(key, 'sha256')\n}\n\nmodule.exports.hashEntry = hashEntry\n\nfunction hashEntry (str) {\n  return hash(str, 'sha1')\n}\n\nfunction hash (str, digest) {\n  return crypto\n    .createHash(digest)\n    .update(str)\n    .digest('hex')\n}\n\nfunction formatEntry (cache, entry, keepAll) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity && !keepAll) {\n    return null\n  }\n\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: entry.integrity ? contentPath(cache, entry.integrity) : undefined,\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata,\n  }\n}\n\nfunction readdirOrEmpty (dir) {\n  return fs.readdir(dir).catch((err) => {\n    if (err.code === 'ENOENT' || err.code === 'ENOTDIR') {\n      return []\n    }\n\n    throw err\n  })\n}\n"],"mappings":"AAAA,YAAY;;AAEZ,MAAMA,IAAI,GAAGC,OAAO,CAAC,MAAM,CAAC;AAC5B,MAAMC,MAAM,GAAGD,OAAO,CAAC,QAAQ,CAAC;AAChC,MAAME,EAAE,GAAGF,OAAO,CAAC,YAAY,CAAC;AAChC,MAAMG,QAAQ,GAAGH,OAAO,CAAC,UAAU,CAAC;AACpC,MAAMI,IAAI,GAAGJ,OAAO,CAAC,MAAM,CAAC;AAC5B,MAAMK,IAAI,GAAGL,OAAO,CAAC,MAAM,CAAC;AAC5B,MAAMM,cAAc,GAAGN,OAAO,CAAC,iBAAiB,CAAC;AAEjD,MAAMO,WAAW,GAAGP,OAAO,CAAC,gBAAgB,CAAC;AAC7C,MAAMQ,QAAQ,GAAGR,OAAO,CAAC,kBAAkB,CAAC;AAC5C,MAAMS,cAAc,GAAGT,OAAO,CAAC,yBAAyB,CAAC;AACzD,MAAMU,MAAM,GAAGV,OAAO,CAAC,iBAAiB,CAAC,CAAC,eAAe,CAAC,CAACW,KAAK;AAChE,MAAMC,QAAQ,GAAGZ,OAAO,CAAC,mBAAmB,CAAC;AAC7C,MAAMa,OAAO,GAAGb,OAAO,CAAC,QAAQ,CAAC;AACjC,MAAMc,MAAM,GAAGf,IAAI,CAACgB,SAAS,CAACF,OAAO,CAAC;AACtCC,MAAM,CAACE,IAAI,GAAGH,OAAO,CAACG,IAAI;AAE1BC,MAAM,CAACC,OAAO,CAACC,aAAa,GAAG,MAAMA,aAAa,SAASC,KAAK,CAAC;EAC/DC,WAAW,CAAEC,KAAK,EAAEC,GAAG,EAAE;IACvB,KAAK,CAAE,sBAAqBA,GAAI,aAAYD,KAAM,EAAC,CAAC;IACpD,IAAI,CAACE,IAAI,GAAG,QAAQ;IACpB,IAAI,CAACF,KAAK,GAAGA,KAAK;IAClB,IAAI,CAACC,GAAG,GAAGA,GAAG;EAChB;AACF,CAAC;AAEDN,MAAM,CAACC,OAAO,CAACO,OAAO,GAAGA,OAAO;AAEhC,eAAeA,OAAO,CAAEH,KAAK,EAAEC,GAAG,EAAEG,OAAO,EAAa;EAAA,IAAXC,IAAI,uEAAG,CAAC,CAAC;EACpD,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAK,EAAEC,GAAG,CAAC;EACrC,MAAMO,OAAO,GAAG,MAAMC,aAAa,CAACH,MAAM,CAAC;EAC3C,MAAMI,UAAU,GAAG,EAAE;EACrB;EACA;EACA,KAAK,IAAIC,CAAC,GAAGH,OAAO,CAACI,MAAM,GAAG,CAAC,EAAED,CAAC,IAAI,CAAC,EAAE,EAAEA,CAAC,EAAE;IAC5C,MAAME,KAAK,GAAGL,OAAO,CAACG,CAAC,CAAC;IACxB;IACA;IACA;IACA;IACA;IACA;IACA;IACA,IAAIE,KAAK,CAACC,SAAS,KAAK,IAAI,IAAI,CAACT,IAAI,CAACU,aAAa,EAAE;MACnD;IACF;;IAEA;IACA;IACA;IACA;IACA,IAAI,CAAC,CAACV,IAAI,CAACU,aAAa,IAAIV,IAAI,CAACU,aAAa,CAACF,KAAK,CAAC,KAAK,IAAI,MAC3DH,UAAU,CAACE,MAAM,KAAK,CAAC,IACtB,CAACF,UAAU,CAACM,IAAI,CAAEC,QAAQ,IAAKb,OAAO,CAACa,QAAQ,EAAEJ,KAAK,CAAC,CAAC,CAAC,EAAE;MAC7DH,UAAU,CAACQ,OAAO,CAACL,KAAK,CAAC;IAC3B;EACF;EAEA,MAAMM,QAAQ,GAAG,IAAI,GAAGT,UAAU,CAACU,GAAG,CAAEP,KAAK,IAAK;IAChD,MAAMQ,WAAW,GAAGC,IAAI,CAACC,SAAS,CAACV,KAAK,CAAC;IACzC,MAAMW,IAAI,GAAGC,SAAS,CAACJ,WAAW,CAAC;IACnC,OAAQ,GAAEG,IAAK,KAAIH,WAAY,EAAC;EAClC,CAAC,CAAC,CAACK,IAAI,CAAC,IAAI,CAAC;EAEb,MAAMC,KAAK,GAAG,YAAY;IACxB,MAAMC,MAAM,GAAG5C,cAAc,CAACF,IAAI,CAAC4C,IAAI,CAAC1B,KAAK,EAAE,KAAK,CAAC,EAAEK,IAAI,CAACwB,SAAS,CAAC;IACtE,MAAM3C,QAAQ,CAAC4C,QAAQ,CAAC9B,KAAK,EAAElB,IAAI,CAACiD,OAAO,CAACH,MAAM,CAAC,CAAC;IACpD,OAAO;MACLA,MAAM;MACNI,KAAK,EAAE;IACT,CAAC;EACH,CAAC;EAED,MAAMC,QAAQ,GAAG,MAAOC,GAAG,IAAK;IAC9B,IAAI,CAACA,GAAG,CAACF,KAAK,EAAE;MACd,OAAOxC,MAAM,CAAC0C,GAAG,CAACN,MAAM,CAAC;IAC3B;EACF,CAAC;EAED,MAAMO,KAAK,GAAG,MAAOD,GAAG,IAAK;IAC3B,MAAMtD,EAAE,CAACwD,SAAS,CAACF,GAAG,CAACN,MAAM,EAAET,QAAQ,EAAE;MAAEkB,IAAI,EAAE;IAAK,CAAC,CAAC;IACxD,MAAMnD,QAAQ,CAAC4C,QAAQ,CAAC9B,KAAK,EAAElB,IAAI,CAACiD,OAAO,CAACzB,MAAM,CAAC,CAAC;IACpD;IACA;IACA,MAAMhB,QAAQ,CAAC4C,GAAG,CAACN,MAAM,EAAEtB,MAAM,CAAC;IAClC4B,GAAG,CAACF,KAAK,GAAG,IAAI;IAChB,IAAI;MACF,MAAM9C,QAAQ,CAACoD,MAAM,CAACtC,KAAK,EAAEM,MAAM,CAAC;IACtC,CAAC,CAAC,OAAOiC,GAAG,EAAE;MACZ,IAAIA,GAAG,CAACrC,IAAI,KAAK,QAAQ,EAAE;QACzB,MAAMqC,GAAG;MACX;IACF;EACF,CAAC;;EAED;EACA,MAAML,GAAG,GAAG,MAAMP,KAAK,EAAE;EACzB,IAAI;IACF,MAAMQ,KAAK,CAACD,GAAG,CAAC;EAClB,CAAC,SAAS;IACR,MAAMD,QAAQ,CAACC,GAAG,CAAC;EACrB;;EAEA;EACA;EACA;EACA;EACA;EACA,OAAOxB,UAAU,CAAC8B,OAAO,EAAE,CAACpB,GAAG,CAAEP,KAAK,IAAK4B,WAAW,CAACzC,KAAK,EAAEa,KAAK,EAAE,IAAI,CAAC,CAAC;AAC7E;AAEAlB,MAAM,CAACC,OAAO,CAAC8C,MAAM,GAAGA,MAAM;AAE9B,eAAeA,MAAM,CAAE1C,KAAK,EAAEC,GAAG,EAAEa,SAAS,EAAa;EAAA,IAAXT,IAAI,uEAAG,CAAC,CAAC;EACrD,MAAM;IAAEsC,QAAQ;IAAEC;EAAK,CAAC,GAAGvC,IAAI;EAC/B,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAK,EAAEC,GAAG,CAAC;EACrC,MAAMY,KAAK,GAAG;IACZZ,GAAG;IACHa,SAAS,EAAEA,SAAS,IAAI/B,IAAI,CAACwC,SAAS,CAACT,SAAS,CAAC;IACjD+B,IAAI,EAAEC,IAAI,CAACC,GAAG,EAAE;IAChBH,IAAI;IACJD;EACF,CAAC;EACD,IAAI;IACF,MAAMzD,QAAQ,CAAC4C,QAAQ,CAAC9B,KAAK,EAAElB,IAAI,CAACiD,OAAO,CAACzB,MAAM,CAAC,CAAC;IACpD,MAAMe,WAAW,GAAGC,IAAI,CAACC,SAAS,CAACV,KAAK,CAAC;IACzC;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA,MAAMjC,EAAE,CAACoE,UAAU,CAAC1C,MAAM,EAAG,KAAImB,SAAS,CAACJ,WAAW,CAAE,KAAIA,WAAY,EAAC,CAAC;IAC1E,MAAMnC,QAAQ,CAACoD,MAAM,CAACtC,KAAK,EAAEM,MAAM,CAAC;EACtC,CAAC,CAAC,OAAOiC,GAAG,EAAE;IACZ,IAAIA,GAAG,CAACrC,IAAI,KAAK,QAAQ,EAAE;MACzB,OAAO+C,SAAS;IAClB;IAEA,MAAMV,GAAG;IACT;IACA;IACA;IACA;IACA;EACF;;EACA,OAAOE,WAAW,CAACzC,KAAK,EAAEa,KAAK,CAAC;AAClC;AAEAlB,MAAM,CAACC,OAAO,CAAC8C,MAAM,CAAChD,IAAI,GAAGwD,UAAU;AAEvC,SAASA,UAAU,CAAElD,KAAK,EAAEC,GAAG,EAAEa,SAAS,EAAa;EAAA,IAAXT,IAAI,uEAAG,CAAC,CAAC;EACnD,MAAM;IAAEsC,QAAQ;IAAEC;EAAK,CAAC,GAAGvC,IAAI;EAC/B,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAK,EAAEC,GAAG,CAAC;EACrC,MAAMY,KAAK,GAAG;IACZZ,GAAG;IACHa,SAAS,EAAEA,SAAS,IAAI/B,IAAI,CAACwC,SAAS,CAACT,SAAS,CAAC;IACjD+B,IAAI,EAAEC,IAAI,CAACC,GAAG,EAAE;IAChBH,IAAI;IACJD;EACF,CAAC;EACDzD,QAAQ,CAAC4C,QAAQ,CAACpC,IAAI,CAACM,KAAK,EAAElB,IAAI,CAACiD,OAAO,CAACzB,MAAM,CAAC,CAAC;EACnD,MAAMe,WAAW,GAAGC,IAAI,CAACC,SAAS,CAACV,KAAK,CAAC;EACzCjC,EAAE,CAACuE,cAAc,CAAC7C,MAAM,EAAG,KAAImB,SAAS,CAACJ,WAAW,CAAE,KAAIA,WAAY,EAAC,CAAC;EACxE,IAAI;IACFnC,QAAQ,CAACoD,MAAM,CAAC5C,IAAI,CAACM,KAAK,EAAEM,MAAM,CAAC;EACrC,CAAC,CAAC,OAAOiC,GAAG,EAAE;IACZ,IAAIA,GAAG,CAACrC,IAAI,KAAK,QAAQ,EAAE;MACzB,MAAMqC,GAAG;IACX;EACF;EACA,OAAOE,WAAW,CAACzC,KAAK,EAAEa,KAAK,CAAC;AAClC;AAEAlB,MAAM,CAACC,OAAO,CAACoB,IAAI,GAAGA,IAAI;AAE1B,eAAeA,IAAI,CAAEhB,KAAK,EAAEC,GAAG,EAAE;EAC/B,MAAMK,MAAM,GAAGC,UAAU,CAACP,KAAK,EAAEC,GAAG,CAAC;EACrC,IAAI;IACF,MAAMO,OAAO,GAAG,MAAMC,aAAa,CAACH,MAAM,CAAC;IAC3C,OAAOE,OAAO,CAAC4C,MAAM,CAAC,CAACC,MAAM,EAAEC,IAAI,KAAK;MACtC,IAAIA,IAAI,IAAIA,IAAI,CAACrD,GAAG,KAAKA,GAAG,EAAE;QAC5B,OAAOwC,WAAW,CAACzC,KAAK,EAAEsD,IAAI,CAAC;MACjC,CAAC,MAAM;QACL,OAAOD,MAAM;MACf;IACF,CAAC,EAAE,IAAI,CAAC;EACV,CAAC,CAAC,OAAOd,GAAG,EAAE;IACZ,IAAIA,GAAG,CAACrC,IAAI,KAAK,QAAQ,EAAE;MACzB,OAAO,IAAI;IACb,CAAC,MAAM;MACL,MAAMqC,GAAG;IACX;EACF;AACF;AAEA5C,MAAM,CAACC,OAAO,CAACoB,IAAI,CAACtB,IAAI,GAAG6D,QAAQ;AAEnC,SAASA,QAAQ,CAAEvD,KAAK,EAAEC,GAAG,EAAE;EAC7B,MAAMK,MAAM,GAAGC,UAAU,CAACP,KAAK,EAAEC,GAAG,CAAC;EACrC,IAAI;IACF,OAAOuD,iBAAiB,CAAClD,MAAM,CAAC,CAAC8C,MAAM,CAAC,CAACC,MAAM,EAAEC,IAAI,KAAK;MACxD,IAAIA,IAAI,IAAIA,IAAI,CAACrD,GAAG,KAAKA,GAAG,EAAE;QAC5B,OAAOwC,WAAW,CAACzC,KAAK,EAAEsD,IAAI,CAAC;MACjC,CAAC,MAAM;QACL,OAAOD,MAAM;MACf;IACF,CAAC,EAAE,IAAI,CAAC;EACV,CAAC,CAAC,OAAOd,GAAG,EAAE;IACZ,IAAIA,GAAG,CAACrC,IAAI,KAAK,QAAQ,EAAE;MACzB,OAAO,IAAI;IACb,CAAC,MAAM;MACL,MAAMqC,GAAG;IACX;EACF;AACF;AAEA5C,MAAM,CAACC,OAAO,CAAC6D,MAAM,GAAGC,GAAG;AAE3B,SAASA,GAAG,CAAE1D,KAAK,EAAEC,GAAG,EAAa;EAAA,IAAXI,IAAI,uEAAG,CAAC,CAAC;EACjC,IAAI,CAACA,IAAI,CAACsD,WAAW,EAAE;IACrB,OAAOjB,MAAM,CAAC1C,KAAK,EAAEC,GAAG,EAAE,IAAI,EAAEI,IAAI,CAAC;EACvC;EAEA,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAK,EAAEC,GAAG,CAAC;EACrC,OAAOT,MAAM,CAACc,MAAM,CAAC;AACvB;AAEAX,MAAM,CAACC,OAAO,CAAC6D,MAAM,CAAC/D,IAAI,GAAGkE,OAAO;AAEpC,SAASA,OAAO,CAAE5D,KAAK,EAAEC,GAAG,EAAa;EAAA,IAAXI,IAAI,uEAAG,CAAC,CAAC;EACrC,IAAI,CAACA,IAAI,CAACsD,WAAW,EAAE;IACrB,OAAOT,UAAU,CAAClD,KAAK,EAAEC,GAAG,EAAE,IAAI,EAAEI,IAAI,CAAC;EAC3C;EAEA,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAK,EAAEC,GAAG,CAAC;EACrC,OAAOT,MAAM,CAACE,IAAI,CAACY,MAAM,CAAC;AAC5B;AAEAX,MAAM,CAACC,OAAO,CAACiE,QAAQ,GAAGA,QAAQ;AAElC,SAASA,QAAQ,CAAE7D,KAAK,EAAE;EACxB,MAAM8D,QAAQ,GAAGC,SAAS,CAAC/D,KAAK,CAAC;EACjC,MAAMgE,MAAM,GAAG,IAAInF,QAAQ,CAAC;IAAEoF,UAAU,EAAE;EAAK,CAAC,CAAC;;EAEjD;EACAC,OAAO,CAACC,OAAO,EAAE,CAACC,IAAI,CAAC,YAAY;IACjC,MAAMC,OAAO,GAAG,MAAMC,cAAc,CAACR,QAAQ,CAAC;IAC9C,MAAMI,OAAO,CAACK,GAAG,CAACF,OAAO,CAACjD,GAAG,CAAC,MAAOd,MAAM,IAAK;MAC9C,MAAMC,UAAU,GAAGzB,IAAI,CAAC4C,IAAI,CAACoC,QAAQ,EAAExD,MAAM,CAAC;MAC9C,MAAMkE,UAAU,GAAG,MAAMF,cAAc,CAAC/D,UAAU,CAAC;MACnD,MAAM2D,OAAO,CAACK,GAAG,CAACC,UAAU,CAACpD,GAAG,CAAC,MAAOqD,SAAS,IAAK;QACpD,MAAMC,aAAa,GAAG5F,IAAI,CAAC4C,IAAI,CAACnB,UAAU,EAAEkE,SAAS,CAAC;;QAEtD;QACA,MAAME,gBAAgB,GAAG,MAAML,cAAc,CAACI,aAAa,CAAC;QAC5D,MAAMR,OAAO,CAACK,GAAG,CAACI,gBAAgB,CAACvD,GAAG,CAAC,MAAOP,KAAK,IAAK;UACtD,MAAM+D,SAAS,GAAG9F,IAAI,CAAC4C,IAAI,CAACgD,aAAa,EAAE7D,KAAK,CAAC;UACjD,IAAI;YACF,MAAML,OAAO,GAAG,MAAMC,aAAa,CAACmE,SAAS,CAAC;YAC9C;YACA;YACA,MAAMC,OAAO,GAAGrE,OAAO,CAAC4C,MAAM,CAAC,CAAC0B,GAAG,EAAEjE,KAAK,KAAK;cAC7CiE,GAAG,CAACC,GAAG,CAAClE,KAAK,CAACZ,GAAG,EAAEY,KAAK,CAAC;cACzB,OAAOiE,GAAG;YACZ,CAAC,EAAE,IAAIE,GAAG,EAAE,CAAC;YACb;YACA,KAAK,MAAMnE,KAAK,IAAIgE,OAAO,CAACI,MAAM,EAAE,EAAE;cACpC,MAAMC,SAAS,GAAGzC,WAAW,CAACzC,KAAK,EAAEa,KAAK,CAAC;cAC3C,IAAIqE,SAAS,EAAE;gBACblB,MAAM,CAAC7B,KAAK,CAAC+C,SAAS,CAAC;cACzB;YACF;UACF,CAAC,CAAC,OAAO3C,GAAG,EAAE;YACZ,IAAIA,GAAG,CAACrC,IAAI,KAAK,QAAQ,EAAE;cACzB,OAAO+C,SAAS;YAClB;YACA,MAAMV,GAAG;UACX;QACF,CAAC,CAAC,CAAC;MACL,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IACHyB,MAAM,CAACmB,GAAG,EAAE;IACZ,OAAOnB,MAAM;EACf,CAAC,CAAC,CAACoB,KAAK,CAAC7C,GAAG,IAAIyB,MAAM,CAACqB,IAAI,CAAC,OAAO,EAAE9C,GAAG,CAAC,CAAC;EAE1C,OAAOyB,MAAM;AACf;AAEArE,MAAM,CAACC,OAAO,CAAC0F,EAAE,GAAGA,EAAE;AAEtB,eAAeA,EAAE,CAAEtF,KAAK,EAAE;EACxB,MAAMQ,OAAO,GAAG,MAAMqD,QAAQ,CAAC7D,KAAK,CAAC,CAACuF,OAAO,EAAE;EAC/C,OAAO/E,OAAO,CAAC4C,MAAM,CAAC,CAAC0B,GAAG,EAAEU,EAAE,KAAK;IACjCV,GAAG,CAACU,EAAE,CAACvF,GAAG,CAAC,GAAGuF,EAAE;IAChB,OAAOV,GAAG;EACZ,CAAC,EAAE,CAAC,CAAC,CAAC;AACR;AAEAnF,MAAM,CAACC,OAAO,CAACa,aAAa,GAAGA,aAAa;AAE5C,eAAeA,aAAa,CAAEH,MAAM,EAAEmF,MAAM,EAAE;EAC5C,MAAMC,IAAI,GAAG,MAAM9G,EAAE,CAAC+G,QAAQ,CAACrF,MAAM,EAAE,MAAM,CAAC;EAC9C,OAAOsF,cAAc,CAACF,IAAI,EAAED,MAAM,CAAC;AACrC;AAEA9F,MAAM,CAACC,OAAO,CAACa,aAAa,CAACf,IAAI,GAAG8D,iBAAiB;AAErD,SAASA,iBAAiB,CAAElD,MAAM,EAAEmF,MAAM,EAAE;EAC1C,MAAMC,IAAI,GAAG9G,EAAE,CAACiH,YAAY,CAACvF,MAAM,EAAE,MAAM,CAAC;EAC5C,OAAOsF,cAAc,CAACF,IAAI,EAAED,MAAM,CAAC;AACrC;AAEA,SAASG,cAAc,CAAEF,IAAI,EAAED,MAAM,EAAE;EACrC,MAAMjF,OAAO,GAAG,EAAE;EAClBkF,IAAI,CAACI,KAAK,CAAC,IAAI,CAAC,CAACC,OAAO,CAAElF,KAAK,IAAK;IAClC,IAAI,CAACA,KAAK,EAAE;MACV;IACF;IAEA,MAAMmF,MAAM,GAAGnF,KAAK,CAACiF,KAAK,CAAC,IAAI,CAAC;IAChC,IAAI,CAACE,MAAM,CAAC,CAAC,CAAC,IAAIvE,SAAS,CAACuE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAKA,MAAM,CAAC,CAAC,CAAC,EAAE;MACpD;MACA;MACA;IACF;IACA,IAAIC,GAAG;IACP,IAAI;MACFA,GAAG,GAAG3E,IAAI,CAAC4E,KAAK,CAACF,MAAM,CAAC,CAAC,CAAC,CAAC;IAC7B,CAAC,CAAC,OAAOG,CAAC,EAAE;MACV;MACA;IACF;IACA,IAAIF,GAAG,EAAE;MACPzF,OAAO,CAAC4F,IAAI,CAACH,GAAG,CAAC;IACnB;EACF,CAAC,CAAC;EACF,OAAOzF,OAAO;AAChB;AAEAb,MAAM,CAACC,OAAO,CAACmE,SAAS,GAAGA,SAAS;AAEpC,SAASA,SAAS,CAAE/D,KAAK,EAAE;EACzB,OAAOlB,IAAI,CAAC4C,IAAI,CAAC1B,KAAK,EAAG,UAASZ,MAAO,EAAC,CAAC;AAC7C;AAEAO,MAAM,CAACC,OAAO,CAACW,UAAU,GAAGA,UAAU;AAEtC,SAASA,UAAU,CAAEP,KAAK,EAAEC,GAAG,EAAE;EAC/B,MAAMoG,MAAM,GAAGC,OAAO,CAACrG,GAAG,CAAC;EAC3B,OAAOnB,IAAI,CAAC4C,IAAI,CAAC6E,KAAK,CACpBzH,IAAI,EACJ,CAACiF,SAAS,CAAC/D,KAAK,CAAC,CAAC,CAACwG,MAAM,CAACrH,cAAc,CAACkH,MAAM,CAAC,CAAC,CAClD;AACH;AAEA1G,MAAM,CAACC,OAAO,CAAC0G,OAAO,GAAGA,OAAO;AAEhC,SAASA,OAAO,CAAErG,GAAG,EAAE;EACrB,OAAOuB,IAAI,CAACvB,GAAG,EAAE,QAAQ,CAAC;AAC5B;AAEAN,MAAM,CAACC,OAAO,CAAC6B,SAAS,GAAGA,SAAS;AAEpC,SAASA,SAAS,CAAEgF,GAAG,EAAE;EACvB,OAAOjF,IAAI,CAACiF,GAAG,EAAE,MAAM,CAAC;AAC1B;AAEA,SAASjF,IAAI,CAAEiF,GAAG,EAAEC,MAAM,EAAE;EAC1B,OAAO/H,MAAM,CACVgI,UAAU,CAACD,MAAM,CAAC,CAClBE,MAAM,CAACH,GAAG,CAAC,CACXC,MAAM,CAAC,KAAK,CAAC;AAClB;AAEA,SAASjE,WAAW,CAAEzC,KAAK,EAAEa,KAAK,EAAEgG,OAAO,EAAE;EAC3C;EACA,IAAI,CAAChG,KAAK,CAACC,SAAS,IAAI,CAAC+F,OAAO,EAAE;IAChC,OAAO,IAAI;EACb;EAEA,OAAO;IACL5G,GAAG,EAAEY,KAAK,CAACZ,GAAG;IACda,SAAS,EAAED,KAAK,CAACC,SAAS;IAC1BhC,IAAI,EAAE+B,KAAK,CAACC,SAAS,GAAG7B,WAAW,CAACe,KAAK,EAAEa,KAAK,CAACC,SAAS,CAAC,GAAGmC,SAAS;IACvEL,IAAI,EAAE/B,KAAK,CAAC+B,IAAI;IAChBC,IAAI,EAAEhC,KAAK,CAACgC,IAAI;IAChBF,QAAQ,EAAE9B,KAAK,CAAC8B;EAClB,CAAC;AACH;AAEA,SAAS2B,cAAc,CAAEwC,GAAG,EAAE;EAC5B,OAAOlI,EAAE,CAACmI,OAAO,CAACD,GAAG,CAAC,CAAC1B,KAAK,CAAE7C,GAAG,IAAK;IACpC,IAAIA,GAAG,CAACrC,IAAI,KAAK,QAAQ,IAAIqC,GAAG,CAACrC,IAAI,KAAK,SAAS,EAAE;MACnD,OAAO,EAAE;IACX;IAEA,MAAMqC,GAAG;EACX,CAAC,CAAC;AACJ"},"metadata":{},"sourceType":"script","externalDependencies":[]}